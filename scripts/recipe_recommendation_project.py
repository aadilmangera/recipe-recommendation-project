# -*- coding: utf-8 -*-
"""recipe_recommendation_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MLpoJfBgkzuehlQBsfJJEM3VIKLhu1Ty

This project implements a recipe recommendation system using machine learning. The dataset is sourced from Kaggle and contains recipes and user interactions. The goal is to recommend recipes based on input ingredients using models such as Cosine Similarity, KNN, and NMF.

DATASET FROM KAGGLE https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions/
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.neighbors import NearestNeighbors
from sklearn.decomposition import NMF
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import make_scorer, accuracy_score
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, MinMaxScaler

recipes_df = pd.read_csv('RAW_recipes.csv')

print(recipes_df.head())

print("\nSummary Statistics:")
print(recipes_df.describe())

print("\nMissing values in each column:")
print(recipes_df.isnull().sum())

"""The dataset includes columns like description and tags that are not needed for this project. These columns are dropped to focus on the key features. Also as description is the only column with missing values, there is no need to handle missing values."""

recipes_df = recipes_df.drop(columns=['description'])
print(recipes_df.head())

"""DATA ANALYSIS
* The bar chart shows the top 10 most common ingredients in the dataset.
* We analyze the distribution of the number of ingredients per recipe to understand the variability in recipe complexity.


"""

from collections import Counter

all_ingredients = [ingredient for sublist in recipes_df['ingredients'] for ingredient in sublist]

ingredient_counts = Counter(all_ingredients)

top_ingredients = ingredient_counts.most_common(10)

ingredients, counts = zip(*top_ingredients)

plt.figure(figsize=(10, 6))
sns.barplot(x=list(counts), y=list(ingredients), palette='viridis')
plt.title('Top 10 Most Common Ingredients')
plt.xlabel('Count')
plt.ylabel('Ingredient')
plt.show()

recipe_lengths = recipes_df['ingredients'].apply(len)

plt.figure(figsize=(10, 6))
sns.histplot(recipe_lengths, bins=30, kde=True, color='blue')
plt.title('Distribution of Number of Ingredients per Recipe')
plt.xlabel('Number of Ingredients')
plt.ylabel('Frequency')
plt.show()

"""PREPROCESSING

* We normalize numerical features like minutes, n_steps, and n_ingredients using MinMaxScaler to scale values between 0 and 1.
* The ingredient lists are converted into text to prepare them for text-based feature extraction.
"""

scaler = MinMaxScaler()
recipes_df = recipes_df.drop(columns=['id', 'contributor_id', 'tags', 'nutrition', 'steps'])
numerical_columns = ['minutes', 'n_steps', 'n_ingredients']
recipes_df[numerical_columns] = scaler.fit_transform(recipes_df[numerical_columns])

recipes_df['ingredients'] = recipes_df['ingredients'].apply(lambda x: x.strip("[]").replace("'", "").split(", "))
recipes_df['ingredients_text'] = recipes_df['ingredients'].apply(lambda x: " ".join(x))

"""FEATURE ENGINEERING
* TF-IDF is used to represent the importance of ingredients in each recipe as numerical features.
* Dimensionality reduction with SVD reduces the TF-IDF matrix to 100 components, which helps improve computational efficiency.


"""

tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(recipes_df['ingredients_text'])

print("TF-IDF Matrix Shape:", tfidf_matrix.shape)

svd = TruncatedSVD(n_components=100)

svd_matrix = svd.fit_transform(tfidf_matrix)

svd_df = pd.DataFrame(svd_matrix, columns=[f"Component_{i+1}" for i in range(svd_matrix.shape[1])])

print(svd_df.head())

"""RECOMMENDATION MODELS

* Cosine Similarity: This method measures similarity between the input ingredients and each recipe by computing the cosine similarity of their TF-IDF vectors.
* KNN: The K-Nearest Neighbors algorithm finds the closest recipes to the input ingredients based on cosine similarity in the TF-IDF space.
* NMF: Non-Negative Matrix Factorization factorizes the TF-IDF matrix into lower-dimensional components. These components are used to recommend recipes.


"""

def precision_at_k(input_ingredients, recommended_recipe_indices, recipes_df, k=5, threshold=0.5):
    relevant_count = 0

    for idx in recommended_recipe_indices[:k]:
        recipe_ingredients = recipes_df.iloc[idx]['ingredients']

        common_ingredients = set(input_ingredients).intersection(set(recipe_ingredients))

        match_fraction = len(common_ingredients) / len(recipe_ingredients)

        if match_fraction >= threshold:
            relevant_count += 1

    precision = relevant_count / k
    return precision

def measure_diversity(recommended_recipe_indices, recipes_df, top_n=5):
    all_ingredients = []
    for idx in recommended_recipe_indices[:top_n]:
        recipe_ingredients = recipes_df.iloc[idx]['ingredients']
        all_ingredients.extend(recipe_ingredients)

    unique_ingredients = len(set(all_ingredients))
    return unique_ingredients / len(all_ingredients)  # diversity ratio

def cosine_recommend_recipes(input_ingredients, tfidf_vectorizer, svd_matrix, top_n=5):
    input_text = " ".join(input_ingredients)
    input_vector = tfidf_vectorizer.transform([input_text])
    input_vector_svd = svd.transform(input_vector)
    cosine_similarities = cosine_similarity(input_vector_svd, svd_matrix).flatten()

    similar_indices = cosine_similarities.argsort()[-top_n:][::-1]

    print("Input Ingredients:", input_ingredients)
    print("\nTop 5 Recommended Recipes:")
    for i, idx in enumerate(similar_indices):
        recipe_name = recipes_df.iloc[idx]['name']
        recipe_ingredients = recipes_df.iloc[idx]['ingredients']
        similarity_score = cosine_similarities[idx]
        print(f"{i+1}. {recipe_name} (Similarity Score: {similarity_score:.4f})")
        print(f"   Ingredients: {recipe_ingredients}")
        print()

    return similar_indices, cosine_similarities[similar_indices]

def knn_recommend_recipes(input_ingredients, tfidf_vectorizer, tfidf_matrix, n_neighbors=5):
    input_text = " ".join(input_ingredients)
    input_vector = tfidf_vectorizer.transform([input_text])

    knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')
    knn.fit(tfidf_matrix)

    distances, indices = knn.kneighbors(input_vector)

    print("Input Ingredients:", input_ingredients)
    print("\nTop 5 Recommended Recipes (KNN):")
    for i, (idx, distance) in enumerate(zip(indices.flatten(), distances.flatten())):
        recipe_name = recipes_df.iloc[idx]['name']
        recipe_ingredients = recipes_df.iloc[idx]['ingredients']
        print(f"{i+1}. {recipe_name} (Cosine Similarity Score: {1 - distance:.4f})")
        print(f"   Ingredients: {recipe_ingredients}")
        print()

    return indices.flatten(), distances.flatten()

def nmf_recommend_recipes(input_ingredients, tfidf_vectorizer, tfidf_matrix, n_components=5, top_n=5):
    input_text = " ".join(input_ingredients)
    input_vector = tfidf_vectorizer.transform([input_text])

    nmf = NMF(n_components=n_components, random_state=42)
    nmf_matrix = nmf.fit_transform(tfidf_matrix)

    input_vector_nmf = nmf.transform(input_vector)
    cosine_similarities = cosine_similarity(input_vector_nmf, nmf_matrix).flatten()

    similar_indices = cosine_similarities.argsort()[-top_n:][::-1]

    print("Input Ingredients:", input_ingredients)
    print("\nTop 5 Recommended Recipes (NMF):")
    for i, idx in enumerate(similar_indices):
        recipe_name = recipes_df.iloc[idx]['name']
        recipe_ingredients = recipes_df.iloc[idx]['ingredients']
        similarity_score = cosine_similarities[idx]
        print(f"{i+1}. {recipe_name} (Similarity Score: {similarity_score:.4f})")
        print(f"   Ingredients: {recipe_ingredients}")
        print()

    return similar_indices, cosine_similarities[similar_indices]

input_ingredients = ['eggs', 'bread', 'butter', 'salt', 'bacon', 'pepper']

"""EVALUATION

* Precision at K measures how many of the top-K recommended recipes are relevant based on shared ingredients.
* Diversity measures the uniqueness of ingredients in the top recommendations to ensure variety in suggestions.
* Time taken for the model to provide the recommendations.

We use precision to evaluate the relevance of the recommendations and diversity to ensure that the recommendations are not overly similar.
"""

start_time = time.time()
recommended_indices_svd, similarity_scores_svd = cosine_recommend_recipes(input_ingredients, tfidf_vectorizer, svd_matrix, top_n=5)
svd_time = time.time() - start_time
precision_svd = precision_at_k(input_ingredients, recommended_indices_svd, recipes_df, k=5, threshold=0.5)
diversity_svd = measure_diversity(recommended_indices_svd, recipes_df, top_n=5)

print("Results for Cosine-based Recommendation:")
print(f"Precision at K (P@5): {precision_svd:.4f}")
print(f"Time taken: {svd_time:.4f} seconds")
print(f"Diversity: {diversity_svd:.4f}\n")

start_time = time.time()
recommended_indices_knn, distances_knn = knn_recommend_recipes(input_ingredients, tfidf_vectorizer, tfidf_matrix, n_neighbors=5)
knn_time = time.time() - start_time
precision_knn = precision_at_k(input_ingredients, recommended_indices_knn, recipes_df, k=5, threshold=0.5)
diversity_knn = measure_diversity(recommended_indices_knn, recipes_df, top_n=5)

print("Results for KNN-based Recommendation:")
print(f"Precision at K (P@5): {precision_knn:.4f}")
print(f"Time taken: {knn_time:.4f} seconds")
print(f"Diversity: {diversity_knn:.4f}\n")

start_time = time.time()
recommended_indices_nmf, distances_nmf = nmf_recommend_recipes(input_ingredients, tfidf_vectorizer, tfidf_matrix, n_components=5, top_n=5)
nmf_time = time.time() - start_time
precision_nmf = precision_at_k(input_ingredients, recommended_indices_nmf, recipes_df, k=5, threshold=0.5)
diversity_nmf = measure_diversity(recommended_indices_nmf, recipes_df, top_n=5)

print("Results for NMF-based Recommendation:")
print(f"Precision at K (P@5): {precision_nmf:.4f}")
print(f"Time taken: {nmf_time:.4f} seconds")
print(f"Diversity: {diversity_nmf:.4f}\n")

"""RESULTS

The table below compares the performance of the models in terms of precision, diversity, and computational time.
"""

comparison_table = pd.DataFrame({
    "Model": ["Cosine + SVD", "KNN", "NMF"],
    "Precision at K (P@5)": [precision_svd, precision_knn, precision_nmf],
    "Time Taken (sec)": [svd_time, knn_time, nmf_time],
    "Diversity": [diversity_svd, diversity_knn, diversity_nmf]
})

print("Comparison Table:")
print(comparison_table)